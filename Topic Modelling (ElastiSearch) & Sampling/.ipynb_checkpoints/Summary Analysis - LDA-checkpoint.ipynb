{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T03:34:27.146318Z",
     "start_time": "2018-04-08T03:34:26.555110Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T03:34:27.654681Z",
     "start_time": "2018-04-08T03:34:27.634487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.kibana': {'aliases': {}},\n",
       " 'news_index': {'aliases': {}},\n",
       " 'p2c_news_index': {'aliases': {}},\n",
       " 'p2b_duc_index': {'aliases': {}},\n",
       " 'p2a_news_index': {'aliases': {}},\n",
       " 'duc_index': {'aliases': {}},\n",
       " 'p2d_duc_index': {'aliases': {}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "logging.getLogger(\"elasticsearch\").setLevel(logging.ERROR)\n",
    "es.indices.get_alias('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T03:34:29.574268Z",
     "start_time": "2018-04-08T03:34:28.409670Z"
    }
   },
   "outputs": [],
   "source": [
    "news_dataset = fetch_20newsgroups(shuffle=True, random_state=1, data_home ='/Users/sarthak/Backup/Data',\n",
    "                             remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T04:14:17.038273Z",
     "start_time": "2018-04-08T04:14:16.955190Z"
    }
   },
   "outputs": [],
   "source": [
    "mypath ='/Users/sarthak/Backup/Data/DUC2001/'\n",
    "gpath = '/Users/sarthak/Backup/Data/DUC2001/Summaries/'\n",
    "datafiles = [(mypath+f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "datalist = []\n",
    "summarylist = []\n",
    "flist = []\n",
    "for item in datafiles:\n",
    "    f = open(item, 'r')\n",
    "    filename = str.lower(item[item.rfind('/')+1:]) + '.txt'\n",
    "    try:\n",
    "        content = f.read()\n",
    "        if content.find('[Text]') > -1:\n",
    "            content = content[content.find('[Text]')+6:]\n",
    "            content = content[:content.find('<')]\n",
    "        else:\n",
    "            content = content[content.find('<TEXT>')+6:]\n",
    "            content = content[:content.find('<')]\n",
    "        datalist.append(content)\n",
    "        if isfile(join(gpath,filename)):\n",
    "            gf = open(gpath+filename, 'r')\n",
    "            gcontent = gf.read()\n",
    "            if gcontent.find('Abstract:') > -1:\n",
    "                gcontent = gcontent[gcontent.find('Abstract:')+10:]\n",
    "            if gcontent.find('Introduction:') > -1:\n",
    "                gcontent = gcontent[gcontent.find('Introduction:')+13:]\n",
    "        else:\n",
    "            gcontent = ''\n",
    "        summarylist.append(gcontent)\n",
    "        flist.append(filename)\n",
    "    except Exception:\n",
    "        pass\n",
    "duc_data = np.array(datalist)\n",
    "duc_sdata = np.array(summarylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T03:34:30.914155Z",
     "start_time": "2018-04-08T03:34:30.911071Z"
    }
   },
   "outputs": [],
   "source": [
    "def kl_divergence(summary_freq, doc_freq):\n",
    "    sum_val = 0\n",
    "    for w in summary_freq:\n",
    "        frequency = doc_freq.get(w)\n",
    "        if frequency:\n",
    "            sum_val += frequency * math.log(frequency / summary_freq[w])\n",
    "    return sum_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T04:41:34.935734Z",
     "start_time": "2018-04-08T04:41:34.924037Z"
    }
   },
   "outputs": [],
   "source": [
    "def init(doc):\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    indexes = count.fit_transform([doc]).toarray().ravel()\n",
    "    lda = LatentDirichletAllocation(n_components=1, \n",
    "                                        max_iter=5,\n",
    "                                        learning_method='online',\n",
    "                                        learning_offset=50.,\n",
    "                                        random_state=0)\n",
    "    _ = lda.fit([indexes])\n",
    "    words = count.get_feature_names()\n",
    "    kl_word_dict = dict(zip(words, indexes))\n",
    "    lda_word_dict = dict(zip(words, lda.components_.ravel()))\n",
    "    return count, lda, kl_word_dict, lda_word_dict\n",
    "\n",
    "def kl_summary_calc(doc, count, kl_word_dict, k):\n",
    "    kl_summary = \"\"\n",
    "    sentance_list = doc.split('.')\n",
    "    for i in range(len(sentance_list)):\n",
    "        kl_div_list = []\n",
    "        for sentance in sentance_list:\n",
    "            current = kl_summary + sentance\n",
    "            try:\n",
    "                wordcount = count.fit_transform([current]).toarray().ravel()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            words = count.get_feature_names()\n",
    "            temp = dict(zip(words, wordcount))\n",
    "            kl_div_list.append(kl_divergence(temp, kl_word_dict))\n",
    "        small = np.array(kl_div_list).argsort()[0]\n",
    "        kl_summary += sentance_list[small] + \" \"\n",
    "        sentance_list.pop(small)\n",
    "        if i == k:\n",
    "            break\n",
    "    return kl_summary\n",
    "\n",
    "def lda_summary_calc(doc, count, lda, kl_word_dict, lda_word_dict, k):\n",
    "    lda_summary = \"\"\n",
    "    sentance_list = doc.split('.')\n",
    "    for i in range(len(sentance_list)):\n",
    "        lda_div_list = []\n",
    "        for sentance in sentance_list:\n",
    "            current = lda_summary + sentance\n",
    "            try:\n",
    "                wordcount = count.fit_transform([current]).toarray().ravel()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            _ = lda.fit([wordcount])\n",
    "            wordcount = lda.components_.ravel()\n",
    "            words = count.get_feature_names()\n",
    "            temp = dict(zip(words, wordcount))\n",
    "            lda_div_list.append(kl_divergence(temp, lda_word_dict))\n",
    "        small = np.array(lda_div_list).argsort()[0]\n",
    "        lda_summary += sentance_list[small] + \" \"\n",
    "        sentance_list.pop(small)\n",
    "        if i == k:\n",
    "            break\n",
    "    return lda_summary\n",
    "\n",
    "def main_function(dataset, k=5):\n",
    "    klist = []\n",
    "    ldalist = []\n",
    "    i=0\n",
    "    for doc in dataset:\n",
    "        try:\n",
    "            i+=1\n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "            count, lda, kl_word_dict, lda_word_dict = init(doc)\n",
    "            kl_summary = kl_summary_calc(doc, count, kl_word_dict, k)\n",
    "            lda_summary = lda_summary_calc(doc, count, lda, kl_word_dict, lda_word_dict, k)\n",
    "            klist.append(kl_summary)\n",
    "            ldalist.append(lda_summary)\n",
    "        except ValueError:\n",
    "            klist.append(\"\")\n",
    "            ldalist.append(\"\")\n",
    "            print('Could not parse document no - ', i)\n",
    "            continue\n",
    "    return klist, ldalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T04:36:33.414311Z",
     "start_time": "2018-04-08T04:36:33.407514Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_es_duc(duc_data, duc_sdata, filenames, klist, ldalist):\n",
    "    request_body = {\n",
    "                    'mappings': {\n",
    "                        '_doc': {\n",
    "                            'properties': {\n",
    "                                'doc_id': {'type': 'text'},\n",
    "                                'doc_text': {'type': 'text'},\n",
    "                                'gold_summary' : {'type': 'text'},\n",
    "                                'kl_summary' : {'type': 'text'},\n",
    "                                'lda_summary' : {'type': 'text'},\n",
    "                                }}}\n",
    "                    }\n",
    "    if es.indices.exists_alias('p3a*'):\n",
    "        print(\"deleting old 'p3a_duc_index' index...\")\n",
    "        es.indices.delete('p3a*')\n",
    "    print(\"creating 'p3a_duc_index' index...\")\n",
    "    es.indices.create(index = 'p3a_duc_index', body = request_body)\n",
    "    for i in range(len(duc_data)):\n",
    "        filename = filenames[i]\n",
    "        content = duc_data[i]\n",
    "        gc = duc_sdata[i]\n",
    "        ks = klist[i]\n",
    "        ls = ldalist[i]\n",
    "        data_dict = {\n",
    "                            \"doc_id\": filename,\n",
    "                            \"doc_text\": content,\n",
    "                            \"gold_summary\": gc,\n",
    "                            \"kl_summary\" : ks,\n",
    "                            \"lda_summary\" : ls\n",
    "                    }\n",
    "        es.index(index='p3a_duc_index', doc_type='_doc', body=data_dict, id=filename, op_type=\"create\")\n",
    "        es.indices.refresh(index='p3a_duc_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T05:16:58.825858Z",
     "start_time": "2018-04-08T05:16:58.819085Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_es_news(news_dataset, klist, ldalist):\n",
    "    request_body = {\n",
    "                    'mappings': {\n",
    "                        '_doc': {\n",
    "                            'properties': {\n",
    "                                'doc_id': {'type': 'text'},\n",
    "                                'doc_text': {'type': 'text'},\n",
    "                                'kl_summary' : {'type': 'text'},\n",
    "                                'lda_summary' : {'type': 'text'},\n",
    "                                }}}\n",
    "                    }\n",
    "    if es.indices.exists_alias('p3b*'):\n",
    "        print(\"deleting old 'p3b_news_index' index...\")\n",
    "        es.indices.delete('p3b*')\n",
    "    print(\"creating 'p3b_news_index' index...\")\n",
    "    es.indices.create(index = 'p3b_news_index', body = request_body)\n",
    "    for i in range(len(news_dataset.data)):\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "        filename = news_dataset.filenames[i][39:]\n",
    "        content = news_dataset.data[i]\n",
    "        ks = klist[i]\n",
    "        ls = ldalist[i]\n",
    "        data_dict = {\n",
    "                            \"doc_id\": filename,\n",
    "                            \"doc_text\": content,\n",
    "                            \"kl_summary\" : ks,\n",
    "                            \"lda_summary\" : ls\n",
    "                    }\n",
    "        es.index(index='p3b_news_index', doc_type='_doc', body=data_dict, id=filename, op_type=\"create\")\n",
    "        es.indices.refresh(index='p3b_news_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T04:38:47.604242Z",
     "start_time": "2018-04-08T04:36:34.419963Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 B 1\n",
      "8 B 2\n",
      "13 B 3\n",
      "16 B 4\n",
      "19 B 5\n",
      "21 B 6\n",
      "28 B 7\n",
      "33 B 8\n",
      "36 B 9\n",
      "39 B 10\n",
      "42 B 11\n",
      "45 B 12\n",
      "52 B 13\n",
      "55 B 14\n",
      "66 B 15\n",
      "71 B 16\n",
      "79 B 17\n",
      "89 B 18\n",
      "91 B 19\n",
      "92 B 20\n",
      "100 B 21\n",
      "105 B 22\n",
      "106 B 23\n",
      "107 B 24\n",
      "111 B 25\n",
      "112 B 26\n",
      "114 B 27\n",
      "118 B 28\n",
      "119 B 29\n",
      "136 B 30\n",
      "137 B 31\n",
      "138 B 32\n",
      "141 B 33\n",
      "143 B 34\n",
      "164 B 35\n",
      "168 B 36\n",
      "183 B 37\n",
      "208 B 38\n",
      "213 B 39\n",
      "217 B 40\n",
      "219 B 41\n",
      "222 B 42\n",
      "235 B 43\n",
      "236 B 44\n",
      "262 B 45\n",
      "266 B 46\n",
      "270 B 47\n",
      "272 B 48\n",
      "280 B 49\n",
      "282 B 50\n",
      "284 B 51\n",
      "285 B 52\n",
      "287 B 53\n",
      "292 B 54\n",
      "296 B 55\n",
      "297 B 56\n",
      "302 B 57\n"
     ]
    }
   ],
   "source": [
    "klist, ldalist = main_function(duc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T04:39:50.997031Z",
     "start_time": "2018-04-08T04:39:46.037862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting old 'p3a_duc_index' index...\n",
      "creating 'p3a_duc_index' index...\n"
     ]
    }
   ],
   "source": [
    "export_es_duc(duc_data, duc_sdata, flist, klist, ldalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T05:15:57.540423Z",
     "start_time": "2018-04-08T04:42:10.273791Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse document no -  52\n",
      "Could not parse document no -  90\n",
      "Could not parse document no -  151\n",
      "Could not parse document no -  256\n",
      "Could not parse document no -  312\n",
      "Could not parse document no -  339\n",
      "Could not parse document no -  360\n",
      "Could not parse document no -  362\n",
      "Could not parse document no -  403\n",
      "Could not parse document no -  409\n",
      "Could not parse document no -  433\n",
      "Could not parse document no -  440\n",
      "Could not parse document no -  441\n",
      "Could not parse document no -  483\n",
      "Could not parse document no -  484\n",
      "Could not parse document no -  501\n",
      "Could not parse document no -  564\n",
      "Could not parse document no -  599\n",
      "Could not parse document no -  665\n",
      "Could not parse document no -  733\n",
      "Could not parse document no -  765\n",
      "Could not parse document no -  810\n",
      "Could not parse document no -  867\n",
      "Could not parse document no -  906\n",
      "Could not parse document no -  913\n",
      "Could not parse document no -  915\n",
      "Could not parse document no -  976\n",
      "1000\n",
      "Could not parse document no -  1015\n",
      "Could not parse document no -  1063\n",
      "Could not parse document no -  1143\n",
      "Could not parse document no -  1191\n",
      "Could not parse document no -  1196\n",
      "Could not parse document no -  1221\n",
      "Could not parse document no -  1256\n",
      "Could not parse document no -  1258\n",
      "Could not parse document no -  1283\n",
      "Could not parse document no -  1297\n",
      "Could not parse document no -  1324\n",
      "Could not parse document no -  1343\n",
      "Could not parse document no -  1372\n",
      "Could not parse document no -  1435\n",
      "Could not parse document no -  1436\n",
      "Could not parse document no -  1439\n",
      "Could not parse document no -  1441\n",
      "Could not parse document no -  1444\n",
      "Could not parse document no -  1480\n",
      "Could not parse document no -  1516\n",
      "Could not parse document no -  1542\n",
      "Could not parse document no -  1585\n",
      "Could not parse document no -  1602\n",
      "Could not parse document no -  1677\n",
      "Could not parse document no -  1688\n",
      "Could not parse document no -  1707\n",
      "Could not parse document no -  1729\n",
      "Could not parse document no -  1732\n",
      "Could not parse document no -  1740\n",
      "Could not parse document no -  1753\n",
      "Could not parse document no -  1764\n",
      "Could not parse document no -  1790\n",
      "Could not parse document no -  1846\n",
      "Could not parse document no -  1862\n",
      "Could not parse document no -  1908\n",
      "2000\n",
      "Could not parse document no -  2026\n",
      "Could not parse document no -  2034\n",
      "Could not parse document no -  2071\n",
      "Could not parse document no -  2168\n",
      "Could not parse document no -  2277\n",
      "Could not parse document no -  2279\n",
      "Could not parse document no -  2289\n",
      "Could not parse document no -  2307\n",
      "Could not parse document no -  2390\n",
      "Could not parse document no -  2392\n",
      "Could not parse document no -  2393\n",
      "Could not parse document no -  2398\n",
      "Could not parse document no -  2437\n",
      "Could not parse document no -  2488\n",
      "Could not parse document no -  2501\n",
      "Could not parse document no -  2505\n",
      "Could not parse document no -  2518\n",
      "Could not parse document no -  2532\n",
      "Could not parse document no -  2534\n",
      "Could not parse document no -  2545\n",
      "Could not parse document no -  2746\n",
      "Could not parse document no -  2778\n",
      "Could not parse document no -  2789\n",
      "Could not parse document no -  2802\n",
      "Could not parse document no -  2925\n",
      "Could not parse document no -  2946\n",
      "Could not parse document no -  2950\n",
      "3000\n",
      "Could not parse document no -  3056\n",
      "Could not parse document no -  3097\n",
      "Could not parse document no -  3101\n",
      "Could not parse document no -  3146\n",
      "Could not parse document no -  3207\n",
      "Could not parse document no -  3232\n",
      "Could not parse document no -  3251\n",
      "Could not parse document no -  3300\n",
      "Could not parse document no -  3336\n",
      "Could not parse document no -  3361\n",
      "Could not parse document no -  3408\n",
      "Could not parse document no -  3418\n",
      "Could not parse document no -  3430\n",
      "Could not parse document no -  3432\n",
      "Could not parse document no -  3495\n",
      "Could not parse document no -  3496\n",
      "Could not parse document no -  3549\n",
      "Could not parse document no -  3664\n",
      "Could not parse document no -  3667\n",
      "Could not parse document no -  3694\n",
      "Could not parse document no -  3711\n",
      "Could not parse document no -  3738\n",
      "Could not parse document no -  3860\n",
      "Could not parse document no -  3888\n",
      "4000\n",
      "Could not parse document no -  4014\n",
      "Could not parse document no -  4054\n",
      "Could not parse document no -  4113\n",
      "Could not parse document no -  4166\n",
      "Could not parse document no -  4237\n",
      "Could not parse document no -  4252\n",
      "Could not parse document no -  4287\n",
      "Could not parse document no -  4300\n",
      "Could not parse document no -  4303\n",
      "Could not parse document no -  4306\n",
      "Could not parse document no -  4341\n",
      "Could not parse document no -  4373\n",
      "Could not parse document no -  4434\n",
      "Could not parse document no -  4446\n",
      "Could not parse document no -  4464\n",
      "Could not parse document no -  4472\n",
      "Could not parse document no -  4517\n",
      "Could not parse document no -  4583\n",
      "Could not parse document no -  4604\n",
      "Could not parse document no -  4618\n",
      "Could not parse document no -  4628\n",
      "Could not parse document no -  4655\n",
      "Could not parse document no -  4688\n",
      "Could not parse document no -  4716\n",
      "Could not parse document no -  4725\n",
      "Could not parse document no -  4746\n",
      "Could not parse document no -  4754\n",
      "Could not parse document no -  4762\n",
      "Could not parse document no -  4804\n",
      "Could not parse document no -  4838\n",
      "Could not parse document no -  4958\n",
      "5000\n",
      "Could not parse document no -  5017\n",
      "Could not parse document no -  5112\n",
      "Could not parse document no -  5145\n",
      "Could not parse document no -  5154\n",
      "Could not parse document no -  5155\n",
      "Could not parse document no -  5215\n",
      "Could not parse document no -  5235\n",
      "Could not parse document no -  5269\n",
      "Could not parse document no -  5319\n",
      "Could not parse document no -  5365\n",
      "Could not parse document no -  5380\n",
      "Could not parse document no -  5385\n",
      "Could not parse document no -  5393\n",
      "Could not parse document no -  5428\n",
      "Could not parse document no -  5527\n",
      "Could not parse document no -  5534\n",
      "Could not parse document no -  5559\n",
      "Could not parse document no -  5607\n",
      "Could not parse document no -  5634\n",
      "Could not parse document no -  5730\n",
      "Could not parse document no -  5795\n",
      "Could not parse document no -  5851\n",
      "Could not parse document no -  5911\n",
      "Could not parse document no -  5997\n",
      "6000\n",
      "Could not parse document no -  6066\n",
      "Could not parse document no -  6075\n",
      "Could not parse document no -  6142\n",
      "Could not parse document no -  6185\n",
      "Could not parse document no -  6193\n",
      "Could not parse document no -  6198\n",
      "Could not parse document no -  6214\n",
      "Could not parse document no -  6249\n",
      "Could not parse document no -  6252\n",
      "Could not parse document no -  6274\n",
      "Could not parse document no -  6279\n",
      "Could not parse document no -  6291\n",
      "Could not parse document no -  6348\n",
      "Could not parse document no -  6431\n",
      "Could not parse document no -  6470\n",
      "Could not parse document no -  6485\n",
      "Could not parse document no -  6528\n",
      "Could not parse document no -  6538\n",
      "Could not parse document no -  6559\n",
      "Could not parse document no -  6574\n",
      "Could not parse document no -  6620\n",
      "Could not parse document no -  6623\n",
      "Could not parse document no -  6656\n",
      "Could not parse document no -  6678\n",
      "Could not parse document no -  6707\n",
      "Could not parse document no -  6761\n",
      "Could not parse document no -  6770\n",
      "Could not parse document no -  6802\n",
      "Could not parse document no -  6813\n",
      "Could not parse document no -  6827\n",
      "Could not parse document no -  6861\n",
      "7000\n",
      "Could not parse document no -  7251\n",
      "Could not parse document no -  7311\n",
      "Could not parse document no -  7402\n",
      "Could not parse document no -  7415\n",
      "Could not parse document no -  7422\n",
      "Could not parse document no -  7434\n",
      "Could not parse document no -  7463\n",
      "Could not parse document no -  7477\n",
      "Could not parse document no -  7489\n",
      "Could not parse document no -  7505\n",
      "Could not parse document no -  7571\n",
      "Could not parse document no -  7584\n",
      "Could not parse document no -  7645\n",
      "Could not parse document no -  7689\n",
      "Could not parse document no -  7703\n",
      "Could not parse document no -  7736\n",
      "Could not parse document no -  7737\n",
      "Could not parse document no -  7757\n",
      "Could not parse document no -  7810\n",
      "Could not parse document no -  7941\n",
      "Could not parse document no -  7948\n",
      "Could not parse document no -  7958\n",
      "Could not parse document no -  7960\n",
      "Could not parse document no -  7982\n",
      "8000\n",
      "Could not parse document no -  8012\n",
      "Could not parse document no -  8015\n",
      "Could not parse document no -  8074\n",
      "Could not parse document no -  8180\n",
      "Could not parse document no -  8212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse document no -  8330\n",
      "Could not parse document no -  8391\n",
      "Could not parse document no -  8407\n",
      "Could not parse document no -  8437\n",
      "Could not parse document no -  8461\n",
      "Could not parse document no -  8575\n",
      "Could not parse document no -  8634\n",
      "Could not parse document no -  8651\n",
      "Could not parse document no -  8711\n",
      "Could not parse document no -  8727\n",
      "Could not parse document no -  8737\n",
      "Could not parse document no -  8773\n",
      "Could not parse document no -  8854\n",
      "Could not parse document no -  8934\n",
      "Could not parse document no -  8955\n",
      "Could not parse document no -  8977\n",
      "Could not parse document no -  8978\n",
      "9000\n",
      "Could not parse document no -  9009\n",
      "Could not parse document no -  9033\n",
      "Could not parse document no -  9072\n",
      "Could not parse document no -  9095\n",
      "Could not parse document no -  9109\n",
      "Could not parse document no -  9210\n",
      "Could not parse document no -  9223\n",
      "Could not parse document no -  9235\n",
      "Could not parse document no -  9238\n",
      "Could not parse document no -  9257\n",
      "Could not parse document no -  9379\n",
      "Could not parse document no -  9400\n",
      "Could not parse document no -  9417\n",
      "Could not parse document no -  9476\n",
      "Could not parse document no -  9491\n",
      "Could not parse document no -  9504\n",
      "Could not parse document no -  9536\n",
      "Could not parse document no -  9540\n",
      "Could not parse document no -  9561\n",
      "Could not parse document no -  9692\n",
      "Could not parse document no -  9730\n",
      "Could not parse document no -  9777\n",
      "Could not parse document no -  9792\n",
      "Could not parse document no -  9905\n",
      "Could not parse document no -  9951\n",
      "Could not parse document no -  9952\n",
      "Could not parse document no -  9980\n",
      "10000\n",
      "Could not parse document no -  10022\n",
      "Could not parse document no -  10033\n",
      "Could not parse document no -  10050\n",
      "Could not parse document no -  10100\n",
      "Could not parse document no -  10139\n",
      "Could not parse document no -  10190\n",
      "Could not parse document no -  10194\n",
      "Could not parse document no -  10199\n",
      "Could not parse document no -  10201\n",
      "Could not parse document no -  10212\n",
      "Could not parse document no -  10221\n",
      "Could not parse document no -  10257\n",
      "Could not parse document no -  10291\n",
      "Could not parse document no -  10303\n",
      "Could not parse document no -  10328\n",
      "Could not parse document no -  10368\n",
      "Could not parse document no -  10386\n",
      "Could not parse document no -  10397\n",
      "Could not parse document no -  10418\n",
      "Could not parse document no -  10426\n",
      "Could not parse document no -  10490\n",
      "Could not parse document no -  10516\n",
      "Could not parse document no -  10571\n",
      "Could not parse document no -  10587\n",
      "Could not parse document no -  10595\n",
      "Could not parse document no -  10623\n",
      "Could not parse document no -  10646\n",
      "Could not parse document no -  10654\n",
      "Could not parse document no -  10694\n",
      "Could not parse document no -  10703\n",
      "Could not parse document no -  10775\n",
      "Could not parse document no -  10811\n",
      "Could not parse document no -  10845\n",
      "Could not parse document no -  10875\n",
      "Could not parse document no -  10916\n",
      "Could not parse document no -  10935\n",
      "11000\n",
      "Could not parse document no -  11036\n",
      "Could not parse document no -  11066\n",
      "Could not parse document no -  11085\n",
      "Could not parse document no -  11134\n",
      "Could not parse document no -  11157\n",
      "Could not parse document no -  11159\n",
      "Could not parse document no -  11226\n",
      "Could not parse document no -  11273\n",
      "Could not parse document no -  11285\n",
      "Could not parse document no -  11311\n"
     ]
    }
   ],
   "source": [
    "klist, ldalist = main_function(news_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T05:19:48.648011Z",
     "start_time": "2018-04-08T05:17:17.164807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting old 'p3b_news_index' index...\n",
      "creating 'p3b_news_index' index...\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "export_es_news(news_dataset, klist, ldalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
