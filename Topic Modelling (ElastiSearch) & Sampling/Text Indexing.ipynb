{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T22:28:31.982371Z",
     "start_time": "2018-04-10T22:28:31.539712Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from elasticsearch import Elasticsearch\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T22:28:32.471259Z",
     "start_time": "2018-04-10T22:28:32.455708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_index': {'aliases': {}},\n",
       " 'p3a_duc_index': {'aliases': {}},\n",
       " 'duc_index': {'aliases': {}},\n",
       " 'p2a_news_index': {'aliases': {}},\n",
       " 'p2b_duc_index': {'aliases': {}},\n",
       " 'p2c_news_index': {'aliases': {}},\n",
       " 'p3b_news_index': {'aliases': {}},\n",
       " '.kibana': {'aliases': {}},\n",
       " 'p2d_duc_index': {'aliases': {}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch()\n",
    "logging.getLogger(\"elasticsearch\").setLevel(logging.ERROR)\n",
    "es.indices.get_alias('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 news group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T17:03:09.501573Z",
     "start_time": "2018-04-07T17:03:08.362094Z"
    }
   },
   "outputs": [],
   "source": [
    "news_dataset = fetch_20newsgroups(data_home ='/Users/sarthak/Backup/Data', shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T17:03:10.295935Z",
     "start_time": "2018-04-07T17:03:10.180397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 'news_index' index...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'news_index'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_body = {\n",
    "                'mappings': {\n",
    "                    '_doc': {\n",
    "                        'properties': {\n",
    "                            'doc_id': {'type': 'text'},\n",
    "                            'doc_text': {'type': 'text'},\n",
    "                            }}}\n",
    "                }\n",
    "print(\"creating 'news_index' index...\")\n",
    "if es.indices.exists_alias('n*'):\n",
    "    es.indices.delete('n*')\n",
    "es.indices.create(index = 'news_index', body = request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T17:05:33.102017Z",
     "start_time": "2018-04-07T17:03:12.821080Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(news_dataset.data)):\n",
    "    data = news_dataset.data[i]\n",
    "    doc_id = news_dataset.filenames[i][39:]\n",
    "    data_dict = {\n",
    "                            \"doc_id\": doc_id,\n",
    "                            \"doc_text\": data\n",
    "                }\n",
    "    es.index(index='news_index', doc_type='_doc', body=data_dict, id=doc_id, op_type=\"create\")\n",
    "    es.indices.refresh(index='news_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T17:05:37.944397Z",
     "start_time": "2018-04-07T17:05:37.937037Z"
    }
   },
   "outputs": [],
   "source": [
    "mypath ='/Users/sarthak/Backup/Data/DUC2001/'\n",
    "gpath = '/Users/sarthak/Backup/Data/DUC2001/Summaries/'\n",
    "datafiles = [(mypath+f) for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T17:05:38.910198Z",
     "start_time": "2018-04-07T17:05:38.791009Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 'duc_index' index...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'duc_index'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_body = {\n",
    "                'mappings': {\n",
    "                    '_doc': {\n",
    "                        'properties': {\n",
    "                            'doc_id': {'type': 'text'},\n",
    "                            'doc_text': {'type': 'text'},\n",
    "                            'gold_summary' : {'type': 'text'},\n",
    "                            }}}\n",
    "                }\n",
    "print(\"creating 'duc_index' index...\")\n",
    "if es.indices.exists_alias('d*'):\n",
    "    es.indices.delete('d*')\n",
    "es.indices.create(index = 'duc_index', body = request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-07T17:05:45.320534Z",
     "start_time": "2018-04-07T17:05:41.167493Z"
    }
   },
   "outputs": [],
   "source": [
    "for item in datafiles:\n",
    "    f = open(item, 'r')\n",
    "    #print(f)\n",
    "    filename = str.lower(item[item.rfind('/')+1:]) + '.txt'\n",
    "    try:\n",
    "        content = f.read()\n",
    "        if content.find('[Text]') > -1:\n",
    "            content = content[content.find('[Text]')+6:]\n",
    "            content = content[:content.find('<')]\n",
    "        else:\n",
    "            content = content[content.find('<TEXT>')+6:]\n",
    "            content = content[:content.find('<')]\n",
    "        if isfile(join(gpath,filename)):\n",
    "            gf = open(gpath+filename, 'r')\n",
    "            gcontent = gf.read()\n",
    "            if gcontent.find('Abstract:') > -1:\n",
    "                gcontent = gcontent[gcontent.find('Abstract:')+10:]\n",
    "            if gcontent.find('Introduction:') > -1:\n",
    "                gcontent = gcontent[gcontent.find('Introduction:')+13:]\n",
    "            data_dict = {\n",
    "                            \"doc_id\": filename,\n",
    "                            \"doc_text\": content,\n",
    "                            \"gold_summary\" : gcontent\n",
    "                        }\n",
    "        else:\n",
    "            data_dict = {\n",
    "                            \"doc_id\": filename,\n",
    "                            \"doc_text\": content,\n",
    "                        }\n",
    "        es.index(index='duc_index', doc_type='_doc', body=data_dict, id=filename, op_type=\"create\")\n",
    "        es.indices.refresh(index='duc_index')\n",
    "    except UnicodeDecodeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
